import matplotlib
matplotlib.use('Agg') # Deve ser chamado ANTES de importar pyplot ou seaborn
import pandas as pd
import numpy as np
import os # Mantido por enquanto, mas verificar uso
from pathlib import Path
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import geopandas as gpd # Mantido, mas verificar se GeoJSON ainda √© usado aqui

# Defini√ß√£o de caminhos relativos √† raiz do projeto
SCRIPT_DIR = Path(__file__).parent # src/pipeline
SRC_DIR = SCRIPT_DIR.parent # src/
PROJECT_ROOT = SRC_DIR.parent # Raiz do projeto

# Diret√≥rios (ajustados)
# RAW_DIR n√£o √© mais necess√°rio aqui
# PROC_DIR agora se refere ao diret√≥rio de sa√≠da para esta fase explorat√≥ria
EXPLORE_RESULTS_DIR = PROJECT_ROOT / "results" / "exploratory_analysis"
EXPLORE_RESULTS_DIR.mkdir(parents=True, exist_ok=True)

# Arquivo de entrada principal (dataset unificado gerado pelo DataCleaner)
UNIFIED_DATASET_PATH = PROJECT_ROOT / "data" / "processed" / "dataset_unificado.csv"
GEOJSON_PATH = PROJECT_ROOT / "data" / "geospatial" / "BR_UF_2024.shp" # Usar o shapefile diretamente

def run_exploratory_analysis():
    print("üöÄ Iniciando Fase de An√°lise Explorat√≥ria (Fase 2 - Explora√ß√£o)...")

    # Carregar dataset unificado
    print(f'üîÑ Carregando dataset unificado de {UNIFIED_DATASET_PATH}...')
    if not UNIFIED_DATASET_PATH.exists():
        print(f"‚ùå ERRO: Dataset unificado {UNIFIED_DATASET_PATH} n√£o encontrado. "
              f"Execute a fase de processamento de dados (DataCleaner) primeiro.")
        return
    
    df_corr = pd.read_csv(UNIFIED_DATASET_PATH)
    print(f"‚úÖ Dataset unificado carregado com {len(df_corr)} linhas e colunas: {df_corr.columns.tolist()}")

    if df_corr.empty:
        print("‚ùå Dataset unificado est√° vazio. Abortando an√°lise explorat√≥ria.")
        return

    # --- 2.1. An√°lise Descritiva (Adaptada) ---
    # As estat√≠sticas detalhadas de IDH e Despesas separadamente podem ser menos relevantes aqui,
    # j√° que temos o dataset unificado. Focaremos nas estat√≠sticas do df_corr.
    print('üìä An√°lise descritiva do dataset unificado...')
    desc_unificado = df_corr.describe(include='all')
    desc_unificado.to_csv(EXPLORE_RESULTS_DIR / 'desc_dataset_unificado.csv')
    print(f"‚úÖ Estat√≠sticas descritivas salvas em: {EXPLORE_RESULTS_DIR / 'desc_dataset_unificado.csv'}")

    # Detec√ß√£o de outliers pode ser mantida se relevante para as colunas principais de df_corr
    # Exemplo para 'idh' e uma coluna de despesa (ex: 'Sa√∫de', se existir, ou uma calculada como 'Gasto Total Normalizado')
    def detectar_outliers(df, col):
        if col not in df.columns:
            print(f"‚ö†Ô∏è Coluna '{col}' n√£o encontrada para detec√ß√£o de outliers.")
            return pd.DataFrame()
        z = (df[col] - df[col].mean()) / df[col].std()
        return df[np.abs(z) > 3]

    if 'idh' in df_corr.columns:
        outliers_idh = detectar_outliers(df_corr, 'idh')
        if not outliers_idh.empty:
            outliers_idh.to_csv(EXPLORE_RESULTS_DIR / 'outliers_idh_unificado.csv', index=False)
            print(f"‚úÖ Outliers de IDH (do unificado) salvos em: {EXPLORE_RESULTS_DIR / 'outliers_idh_unificado.csv'}")
    
    # Exemplo de coluna de despesa. O nome exato pode variar dependendo do DataCleaner.
    # Vamos assumir que existe uma coluna como 'despesa_saude_per_capita' ou similar.
    # Ou, se tivermos calculado 'Gasto Total Normalizado' no DataCleaner, poder√≠amos us√°-la.
    # Por agora, deixarei um placeholder ou voc√™ pode especificar qual usar.
    col_despesa_exemplo = 'Sa√∫de' # Tentar com a coluna base. Ajustar se o nome for diferente no CSV. 
                                 # No CSV unificado, as colunas de despesa s√£o s√≥ os nomes das √°reas.
    if col_despesa_exemplo in df_corr.columns:
        outliers_despesa = detectar_outliers(df_corr, col_despesa_exemplo)
        if not outliers_despesa.empty:
            outliers_despesa.to_csv(EXPLORE_RESULTS_DIR / f'outliers_{col_despesa_exemplo.lower()}_unificado.csv', index=False)
            print(f"‚úÖ Outliers de {col_despesa_exemplo} (do unificado) salvos.")
    else:
        print(f"‚ö†Ô∏è Coluna '{col_despesa_exemplo}' n√£o encontrada para an√°lise de outliers de despesa.")

    # --- 2.2. An√°lise de Correla√ß√µes (Mantida, usando df_corr) ---
    print('üîó An√°lise de correla√ß√µes (sobre dataset unificado)...')
    
    # Nomes t√©cnicos das colunas de despesa (como s√£o geradas pelo fase1b_clean_data)
    despesa_cols_tecnicas = {
        'Sa√∫de': 'despesa_saude',
        'Educa√ß√£o': 'despesa_educacao',
        'Assist√™ncia Social': 'despesa_assistencia_social',
        'Infraestrutura': 'despesa_infraestrutura'
    }
    
    # Filtrar para categorias cujas colunas t√©cnicas realmente existem em df_corr
    # categorias_existentes agora ser√° uma lista de nomes amig√°veis (ex: 'Sa√∫de')
    # cujas colunas t√©cnicas correspondentes (ex: 'despesa_saude') est√£o no DataFrame.
    categorias_existentes_map = { 
        nome_amigavel: nome_tecnico 
        for nome_amigavel, nome_tecnico in despesa_cols_tecnicas.items() 
        if nome_tecnico in df_corr.columns
    }

    if not categorias_existentes_map:
        print("‚ö†Ô∏è Nenhuma das colunas de categoria de despesa esperadas (ex: despesa_saude) foi encontrada no dataset unificado.")
    else:
        print(f"‚ÑπÔ∏è Categorias de despesa encontradas e mapeadas para an√°lise: {list(categorias_existentes_map.keys())}")
        correlacoes = {}
        for nome_amigavel, nome_tecnico in categorias_existentes_map.items():
            correlacoes[nome_amigavel] = {
                'pearson': df_corr['idh'].corr(df_corr[nome_tecnico], method='pearson'),
                'spearman': df_corr['idh'].corr(df_corr[nome_tecnico], method='spearman')
            }
        pd.DataFrame(correlacoes).to_csv(EXPLORE_RESULTS_DIR / 'correlacoes_por_categoria.csv')
        print(f"‚úÖ Correla√ß√µes por categoria salvas.")

        # Correla√ß√£o por ano
        if 'ano' in df_corr.columns:
            correlacoes_ano = []
            for ano_val in sorted(df_corr['ano'].unique()):
                linha = {'ano': ano_val}
                sub = df_corr[df_corr['ano'] == ano_val]
                for nome_amigavel, nome_tecnico in categorias_existentes_map.items():
                    linha[f'{nome_amigavel}_pearson'] = sub['idh'].corr(sub[nome_tecnico], method='pearson')
                    linha[f'{nome_amigavel}_spearman'] = sub['idh'].corr(sub[nome_tecnico], method='spearman')
                correlacoes_ano.append(linha)
            pd.DataFrame(correlacoes_ano).to_csv(EXPLORE_RESULTS_DIR / 'correlacoes_por_ano.csv', index=False)
            print(f"‚úÖ Correla√ß√µes por ano salvas.")

        # Correla√ß√£o por estado (uf)
        if 'uf' in df_corr.columns:
            correlacoes_estado = []
            for uf_val in sorted(df_corr['uf'].unique()):
                linha = {'uf': uf_val}
                sub = df_corr[df_corr['uf'] == uf_val]
                for nome_amigavel, nome_tecnico in categorias_existentes_map.items():
                    linha[f'{nome_amigavel}_pearson'] = sub['idh'].corr(sub[nome_tecnico], method='pearson')
                    linha[f'{nome_amigavel}_spearman'] = sub['idh'].corr(sub[nome_tecnico], method='spearman')
                correlacoes_estado.append(linha)
            pd.DataFrame(correlacoes_estado).to_csv(EXPLORE_RESULTS_DIR / 'correlacoes_por_estado.csv', index=False)
            print(f"‚úÖ Correla√ß√µes por estado salvas.")

        # Correla√ß√£o por regi√£o
        if 'regiao' in df_corr.columns: # A coluna 'regiao' deve vir do dataset unificado
            correlacoes_regiao = []
            for reg_val in sorted(df_corr['regiao'].dropna().unique()):
                linha = {'regiao': reg_val}
                sub = df_corr[df_corr['regiao'] == reg_val]
                for nome_amigavel, nome_tecnico in categorias_existentes_map.items():
                    linha[f'{nome_amigavel}_pearson'] = sub['idh'].corr(sub[nome_tecnico], method='pearson')
                    linha[f'{nome_amigavel}_spearman'] = sub['idh'].corr(sub[nome_tecnico], method='spearman')
                correlacoes_regiao.append(linha)
            pd.DataFrame(correlacoes_regiao).to_csv(EXPLORE_RESULTS_DIR / 'correlacoes_por_regiao.csv', index=False)
            print(f"‚úÖ Correla√ß√µes por regi√£o salvas.")
        else:
            print("‚ö†Ô∏è Coluna 'regiao' n√£o encontrada no df_corr. N√£o foi poss√≠vel calcular correla√ß√µes por regi√£o.")

    # --- 2.3. Prepara√ß√£o para Visualiza√ß√µes (Simplificada) ---
    # Algumas agrega√ß√µes e varia√ß√µes j√° podem estar no dataset unificado ou ser parte da Fase 3.
    # Vamos manter a gera√ß√£o de arquivos CSV que podem ser √∫teis para relat√≥rios.
    print('üõ†Ô∏è Preparando dados agregados e m√©tricas derivadas (do dataset unificado)...')
    if 'regiao' in df_corr.columns and 'ano' in df_corr.columns and 'idh' in df_corr.columns:
        df_idh_reg = df_corr.groupby(['ano', 'regiao'], as_index=False)['idh'].mean()
        df_idh_reg.to_csv(EXPLORE_RESULTS_DIR / 'idh_por_regiao_exploratorio.csv', index=False)
        print(f"‚úÖ IDH por regi√£o (explorat√≥rio) salvo.")

    # A coluna 'populacao' √© crucial para gr√°ficos de bolha e c√°lculos per capita.
    # Ela deve estar no dataset_unificado.csv
    if 'populacao' not in df_corr.columns:
        print("‚ö†Ô∏è Coluna 'populacao' n√£o encontrada no df_corr. Alguns gr√°ficos podem falhar ou ser imprecisos.")

    # --- Gr√°ficos Explorat√≥rios (salvar como PNG e HTML) ---
    print('üìà Gerando gr√°ficos explorat√≥rios...')
    sns.set(style='whitegrid')
    
    if 'regiao' in df_corr.columns and 'idh' in df_corr.columns:
        plt.figure(figsize=(10,6))
        sns.boxplot(x='regiao', y='idh', data=df_corr)
        plt.title('Distribui√ß√£o do IDH por Regi√£o (Dataset Unificado)')
        plt.savefig(EXPLORE_RESULTS_DIR / 'boxplot_idh_regiao.png')
        plt.close()
        print("‚úÖ Boxplot IDH por Regi√£o salvo.")

    # Scatterplot IDH vs. gastos (agora usando colunas existentes em df_corr)
    for nome_amigavel, nome_tecnico in categorias_existentes_map.items():
        if 'idh' in df_corr.columns:
            plt.figure(figsize=(8,6))
            sns.scatterplot(x=nome_tecnico, y='idh', data=df_corr, hue='regiao' if 'regiao' in df_corr.columns else None, alpha=0.7)
            plt.title(f'IDH vs. Gastos em {nome_amigavel}')
            plt.xlabel(f'Gasto em {nome_amigavel}')
            plt.ylabel('IDH')
            plt.savefig(EXPLORE_RESULTS_DIR / f'scatter_idh_vs_gasto_{nome_amigavel.lower().replace(" ", "_").replace("√£", "a").replace("√ß", "c")}.png')
            plt.close()
            print(f"‚úÖ Scatterplot IDH vs {nome_amigavel} salvo.")

    # Heatmap de correla√ß√£o (j√° calculado, agora plotando)
    # Selecionar apenas as colunas t√©cnicas de despesa que existem, mais o IDH
    cols_tecnicas_para_heatmap = ['idh'] + [nome_tecnico for nome_tecnico in categorias_existentes_map.values()]
    
    if len(cols_tecnicas_para_heatmap) > 1: # Precisa de pelo menos duas colunas para correlacionar
        # Para o heatmap, vamos usar os nomes amig√°veis nos r√≥tulos para melhor visualiza√ß√£o
        df_heatmap_plot = df_corr[cols_tecnicas_para_heatmap].copy()
        rename_for_heatmap_plot = {'idh': 'IDH'} # Come√ßa com IDH
        for nome_amigavel, nome_tecnico in categorias_existentes_map.items():
            rename_for_heatmap_plot[nome_tecnico] = nome_amigavel # Mapeia de 'despesa_saude' para 'Sa√∫de'
        df_heatmap_plot.rename(columns=rename_for_heatmap_plot, inplace=True)
        
        plt.figure(figsize=(10,8)) # Ajustado tamanho para melhor visualiza√ß√£o dos r√≥tulos
        sns.heatmap(df_heatmap_plot.corr(), annot=True, cmap='coolwarm', fmt=".2f", vmin=-1, vmax=1)
        plt.title('Heatmap de Correla√ß√£o (Dataset Unificado)')
        plt.tight_layout()
        plt.savefig(EXPLORE_RESULTS_DIR / 'heatmap_correlacao_unificado.png')
        plt.close()
        print(f"‚úÖ Heatmap de Correla√ß√£o salvo.")

    # --- Mapas Interativos (Adaptado) ---
    print('üåé Gerando mapas interativos (explorat√≥rios)...')

    # Mapa de Calor Relacional (Heatmap de correla√ß√£o interativo)
    if len(cols_tecnicas_para_heatmap) > 1:
        # Reutilizando df_heatmap_plot que j√° tem nomes amig√°veis
        heatmap_fig_px = px.imshow(
            df_heatmap_plot.corr(), # Usa o DataFrame com nomes amig√°veis
            text_auto=True, # Mostra os valores de correla√ß√£o no heatmap
            color_continuous_scale='RdBu_r', # Inverte para vermelho=positivo, azul=negativo
            aspect="auto",
            labels=dict(color="Correla√ß√£o"),
            title='Heatmap Interativo: Correla√ß√£o entre IDH e Gastos'
        )
        heatmap_fig_px.update_xaxes(title_text='')
        heatmap_fig_px.update_yaxes(title_text='')
        heatmap_fig_px.write_html(EXPLORE_RESULTS_DIR / 'heatmap_interativo_correlacao.html')
        print(f"‚úÖ Heatmap interativo de correla√ß√£o salvo.")

    # Gr√°fico de Bolhas Cruzado (IDH vs. gasto, tamanho=popula√ß√£o)
    if 'populacao' in df_corr.columns and 'ano' in df_corr.columns and 'uf' in df_corr.columns and 'regiao' in df_corr.columns and 'idh' in df_corr.columns:
        for nome_amigavel, nome_tecnico in categorias_existentes_map.items():
            bolha_fig = px.scatter(
                df_corr.sort_values(by='ano'), # Garante ordem para anima√ß√£o
                x=nome_tecnico, # Usa o nome t√©cnico da coluna para buscar os dados
                y='idh',
                size='populacao', 
                color='regiao',
                hover_name='uf',
                animation_frame='ano',
                animation_group='uf',
                log_x=True, # Gastos podem ter grande varia√ß√£o
                size_max=60,
                title=f'Gr√°fico de Bolhas: IDH vs. Gasto em {nome_amigavel}',
                labels={nome_tecnico: f'Gasto em {nome_amigavel} (log)', 'idh': 'IDH', 'populacao': 'Popula√ß√£o'} # Usa nome t√©cnico na key do label, amig√°vel no value
            )
            bolha_fig.write_html(EXPLORE_RESULTS_DIR / f'bolhas_idh_vs_gasto_{nome_amigavel.lower().replace(" ", "_").replace("√£", "a").replace("√ß", "c")}.html')
            print(f"‚úÖ Gr√°fico de bolhas IDH vs {nome_amigavel} salvo.")
    else:
        print("‚ö†Ô∏è N√£o foi poss√≠vel gerar gr√°ficos de bolhas devido √† falta de colunas: 'populacao', 'ano', 'uf', 'regiao' ou 'idh'.")

    # Mapa Coropl√©tico (Simplificado para IDH e um exemplo de Gasto do ano mais recente)
    if GEOJSON_PATH.exists() and 'uf' in df_corr.columns and 'ano' in df_corr.columns:
        try:
            geo_data = gpd.read_file(GEOJSON_PATH)
            # Padronizar coluna de UF no shapefile
            if 'SIGLA_UF' in geo_data.columns:
                geo_data = geo_data.rename(columns={'SIGLA_UF': 'uf'})
            elif 'CD_UF' in geo_data.columns: # Outro nome comum
                 geo_data = geo_data.rename(columns={'CD_UF': 'uf'})
            elif 'SIGLA' in geo_data.columns:
                 geo_data = geo_data.rename(columns={'SIGLA': 'uf'})
            
            if 'uf' not in geo_data.columns:
                raise ValueError("Coluna 'uf' n√£o encontrada no shapefile ap√≥s tentativas de renomea√ß√£o.")
            
            geo_data['uf'] = geo_data['uf'].astype(str).str.upper()
            df_corr['uf'] = df_corr['uf'].astype(str).str.upper()
            
            ano_max = df_corr['ano'].max()
            df_map = df_corr[df_corr['ano'] == ano_max].copy()

            if 'idh' in df_map.columns:
                fig_idh_map = px.choropleth_mapbox(
                    df_map, geojson=geo_data, locations='uf', featureidkey='properties.uf',
                    color='idh', color_continuous_scale="Viridis",
                    mapbox_style="carto-positron", zoom=3, center = {"lat": -14.24, "lon": -51.925},
                    opacity=0.7, hover_name='uf',
                    title=f'Mapa Coropl√©tico: IDH por Estado ({ano_max})',
                    hover_data={'idh':True, 'regiao': True if 'regiao' in df_map.columns else False} # Ajustado para df_map.columns
                )
                fig_idh_map.update_layout(margin={"r":0,"t":30,"l":0,"b":0})
                fig_idh_map.write_html(EXPLORE_RESULTS_DIR / f'mapa_coropletico_idh_{ano_max}.html')
                print(f"‚úÖ Mapa coropl√©tico de IDH ({ano_max}) salvo.")

            # Exemplo com uma categoria de gasto
            if categorias_existentes_map: # Verifica se o mapa n√£o est√° vazio
                # Pega o primeiro nome amig√°vel e seu correspondente t√©cnico para o mapa de exemplo
                primeiro_nome_amigavel = list(categorias_existentes_map.keys())[0]
                primeiro_nome_tecnico = categorias_existentes_map[primeiro_nome_amigavel]
                
                if primeiro_nome_tecnico in df_map.columns:
                    fig_gasto_map = px.choropleth_mapbox(
                        df_map, geojson=geo_data, locations='uf', featureidkey='properties.uf',
                        color=primeiro_nome_tecnico, # Usa o nome t√©cnico da coluna
                        color_continuous_scale="Blues",
                        mapbox_style="carto-positron", zoom=3, center = {"lat": -14.24, "lon": -51.925},
                        opacity=0.7, hover_name='uf',
                        title=f'Mapa Coropl√©tico: Gasto em {primeiro_nome_amigavel} por Estado ({ano_max})',
                        hover_data={'idh':True, primeiro_nome_tecnico:True, 'regiao': True if 'regiao' in df_map.columns else False} # Ajustado para df_map.columns
                    )
                    fig_gasto_map.update_layout(margin={"r":0,"t":30,"l":0,"b":0})
                    fig_gasto_map.write_html(EXPLORE_RESULTS_DIR / f'mapa_coropletico_gasto_{primeiro_nome_amigavel.lower().replace(" ", "_").replace("√£", "a").replace("√ß", "c")}_{ano_max}.html')
                    print(f"‚úÖ Mapa coropl√©tico de Gasto ({primeiro_nome_amigavel}, {ano_max}) salvo.")
        except Exception as e_map:
            print(f"‚ö†Ô∏è Erro ao gerar mapas coropl√©ticos: {e_map}. Verifique o arquivo shapefile e as colunas.")

    else:
        print('‚ö†Ô∏è Shapefile n√£o encontrado ou colunas de UF/ano ausentes. Mapas coropl√©ticos n√£o ser√£o gerados.')

    print(f'‚úÖ An√°lise Explorat√≥ria (Fase 2 - Explora√ß√£o) conclu√≠da! Arquivos salvos em {EXPLORE_RESULTS_DIR.relative_to(PROJECT_ROOT)}.')

if __name__ == '__main__':
    run_exploratory_analysis() 