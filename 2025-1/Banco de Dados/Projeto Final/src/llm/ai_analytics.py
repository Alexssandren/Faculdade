"""
M√≥dulo de IA Anal√≠tica - Fase 4
Sistema avan√ßado de an√°lise com IA integrada √†s consultas da Fase 3
"""
import os
import google.generativeai as genai
from dotenv import load_dotenv
import json
import pandas as pd
from pathlib import Path
import re
from typing import Dict, List, Optional, Tuple
import logging
from datetime import datetime

# Configurar logging
logger = logging.getLogger(__name__)

class AIAnalyticsEngine:
    """
    Motor de IA para an√°lises socioecon√¥micas avan√ßadas.
    Integra com as consultas anal√≠ticas da Fase 3.
    """
    
    def __init__(self):
        """Inicializa o motor de IA anal√≠tica."""
        self._setup_gemini()
        self._load_data()
        self.conversation_history = []
        self.analysis_cache = {}
        
    def _setup_gemini(self):
        """Configura a API do Google Gemini."""
        try:
            # Encontrar arquivo .env
            current_dir = Path(__file__).parent
            while current_dir != current_dir.parent:
                dotenv_path = current_dir / "Chave.env"
                if dotenv_path.exists():
                    load_dotenv(dotenv_path=dotenv_path)
                    break
                current_dir = current_dir.parent
            
            self.api_key = os.getenv("GEMINI_API_KEY")
            if not self.api_key:
                raise ValueError("GEMINI_API_KEY n√£o encontrada no arquivo .env")
            
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-1.5-flash')
            logger.info("‚úÖ Gemini configurado com sucesso")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao configurar Gemini: {e}")
            raise
    
    def _load_data(self):
        """Carrega dados do banco via consultas anal√≠ticas."""
        try:
            from src.queries.analytics_queries import ConsultasAnal√≠ticas
            from src.database.connection import get_database_connection
            
            # Inicializar sistema anal√≠tico
            self.analytics = ConsultasAnal√≠ticas()
            self.db_connection = get_database_connection()
            
            # Verificar se h√° dados dispon√≠veis
            with self.db_connection.get_session() as session:
                from src.models.entities import IndicadorIDH, Despesa
                
                total_idh = session.query(IndicadorIDH).count()
                total_despesas = session.query(Despesa).count()
                
                if total_idh == 0 or total_despesas == 0:
                    logger.warning(f"‚ö†Ô∏è Dados insuficientes no banco: {total_idh} IDH, {total_despesas} despesas")
                    self.data_available = False
                else:
                    logger.info(f"‚úÖ Dados carregados do banco: {total_idh} registros IDH, {total_despesas} registros despesas")
                    self.data_available = True
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar dados do banco: {e}")
            self.analytics = None
            self.db_connection = None
            self.data_available = False
    
    def analyze_with_ai(self, query: str, context_data: Dict = None) -> Dict:
        """
        An√°lise principal com IA integrada.
        
        Args:
            query: Pergunta do usu√°rio
            context_data: Dados de contexto das consultas da Fase 3
            
        Returns:
            Dict com an√°lise completa
        """
        try:
            # Preparar contexto anal√≠tico
            enriched_prompt = self._create_analytical_prompt(query, context_data)
            
            # Gerar resposta com Gemini
            response = self.model.generate_content(
                enriched_prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.3,
                    max_output_tokens=2000,
                )
            )
            
            # Processar resposta
            analysis = self._process_ai_response(response.text, query, context_data)
            
            # Adicionar ao hist√≥rico
            self._add_to_history(query, analysis)
            
            return analysis
            
        except Exception as e:
            error_msg = str(e) if str(e) else "Erro desconhecido na an√°lise"
            # Evitar erro vazio ("0")
            if not error_msg or error_msg.strip() == "0":
                error_msg = "Erro inesperado durante a an√°lise. Verifique os dados de entrada."
            logger.error(f"‚ùå Erro na an√°lise: {error_msg}")
            return self._create_error_response(error_msg)
    
    def _create_analytical_prompt(self, query: str, context_data: Dict = None) -> str:
        """Cria prompt anal√≠tico enriquecido."""
        
        base_prompt = f"""
        Voc√™ √© um ANALISTA S√äNIOR especializado em dados socioecon√¥micos brasileiros.
        
        üéØ ESPECIALIDADES:
        - An√°lise de IDH (√çndice de Desenvolvimento Humano)
        - Despesas p√∫blicas federais
        - Compara√ß√µes regionais e estaduais
        - Efici√™ncia de investimentos
        - Tend√™ncias e proje√ß√µes
        
        üìä CONSULTA DO USU√ÅRIO: {query}
        
        """
        
        # Adicionar contexto das consultas anal√≠ticas do banco
        if context_data and self.data_available:
            base_prompt += "\nüîç CONTEXTO ANAL√çTICO DO BANCO DE DADOS:\n"
            
            if 'consulta_1' in context_data:
                ranking_data = context_data['consulta_1']
                base_prompt += f"üìà RANKING IDH vs INVESTIMENTO (Consulta Anal√≠tica 1):\n"
                
                # Verificar se h√° dados v√°lidos
                correlation = ranking_data.get('correlation', 0)
                if correlation and not (isinstance(correlation, float) and str(correlation) == 'nan'):
                    base_prompt += f"- Correla√ß√£o IDH vs Despesas: {correlation:.3f}\n"
                else:
                    base_prompt += f"- Correla√ß√£o IDH vs Despesas: dados insuficientes\n"
                
                total_states = ranking_data.get('total_states', 0)
                base_prompt += f"- {total_states} estados analisados\n"
                
                # Adicionar dados espec√≠ficos se dispon√≠veis
                if 'estados' in ranking_data and ranking_data['estados']:
                    base_prompt += f"- Estados com dados: {', '.join(ranking_data['estados'][:5])}\n"
            
            if 'consulta_2' in context_data:
                temporal_data = context_data['consulta_2']
                base_prompt += f"üìÖ EVOLU√á√ÉO TEMPORAL (Consulta Anal√≠tica 2):\n"
                
                years = temporal_data.get('years', [])
                if years:
                    base_prompt += f"- Per√≠odo analisado: {min(years)}-{max(years)}\n"
                
                growth_rate = temporal_data.get('growth_rate', 0)
                if growth_rate:
                    base_prompt += f"- Taxa de crescimento m√©dio: {growth_rate:.2f}%\n"
                
                total_records = temporal_data.get('total_records', 0)
                base_prompt += f"- {total_records} registros temporais\n"
            
            if 'consulta_3' in context_data:
                regional_data = context_data['consulta_3']
                base_prompt += f"üó∫Ô∏è AN√ÅLISE REGIONAL (Consulta Anal√≠tica 3):\n"
                
                if 'regioes' in regional_data and regional_data['regioes']:
                    base_prompt += f"- Regi√µes: {', '.join(regional_data['regioes'])}\n"
                
                if 'idh_values' in regional_data and regional_data['idh_values']:
                    idh_values = regional_data['idh_values']
                    if idh_values:
                        base_prompt += f"- IDH m√©dio nacional: {sum(idh_values)/len(idh_values):.3f}\n"
                        base_prompt += f"- Varia√ß√£o IDH: {min(idh_values):.3f} - {max(idh_values):.3f}\n"
                
                total_records = regional_data.get('total_records', 0)
                base_prompt += f"- {total_records} registros regionais\n"
        
        elif not self.data_available:
            base_prompt += "\n‚ö†Ô∏è AVISO: Dados do banco n√£o dispon√≠veis. An√°lise limitada.\n"
        
        base_prompt += """
        
        üìã INSTRU√á√ïES PARA RESPOSTA:
        1. Forne√ßa insights baseados nos dados reais dispon√≠veis
        2. Use linguagem t√©cnica mas acess√≠vel
        3. Inclua recomenda√ß√µes pr√°ticas e espec√≠ficas
        4. Cite m√©tricas concretas quando poss√≠vel
        5. Identifique padr√µes, tend√™ncias e anomalias
        6. Sugira pr√≥ximos passos ou an√°lises complementares
        
        üìä ESTRUTURA DA RESPOSTA:
        - An√°lise principal (2-3 par√°grafos)
        - Insights espec√≠ficos (3-5 pontos)
        - Recomenda√ß√µes pr√°ticas (2-3 a√ß√µes)
        - M√©tricas de destaque
        
        IMPORTANTE: Seja espec√≠fico, pr√°tico e baseado em dados.
        """
        
        return base_prompt
    
    def _process_ai_response(self, response_text: str, query: str, context_data: Dict) -> Dict:
        """Processa a resposta da IA."""
        
        # Extrair insights estruturados
        insights = self._extract_insights(response_text)
        
        # Extrair recomenda√ß√µes
        recommendations = self._extract_recommendations(response_text)
        
        # Determinar tipo de an√°lise
        analysis_type = self._determine_analysis_type(query)
        
        # Extrair m√©tricas mencionadas
        metrics = self._extract_metrics(response_text)
        
        # Calcular score de confian√ßa
        confidence_score = self._calculate_confidence(response_text, context_data)
        
        # Sugerir visualiza√ß√µes
        viz_suggestions = self._suggest_visualizations(analysis_type, query)
        
        return {
            'response_text': response_text,
            'insights': insights,
            'recommendations': recommendations,
            'analysis_type': analysis_type,
            'metrics_mentioned': metrics,
            'confidence_score': confidence_score,
            'visualization_suggestions': viz_suggestions,
            'timestamp': datetime.now().isoformat(),
            'query_original': query,
            'has_context_data': bool(context_data)
        }
    
    def _extract_insights(self, text: str) -> List[str]:
        """Extrai insights principais do texto."""
        insights = []
        
        # Padr√µes para identificar insights
        patterns = [
            r'[Ii]nsight[:\s]+([^.]+)',
            r'[Dd]escobri[:\s]+([^.]+)',
            r'[Oo]bservamos?\s+que\s+([^.]+)',
            r'√â\s+importante\s+notar\s+que\s+([^.]+)',
            r'[Dd]estaca-se\s+([^.]+)'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            insights.extend([match.strip() for match in matches])
        
        # Limitar a 5 insights principais
        return insights[:5]
    
    def _extract_recommendations(self, text: str) -> List[str]:
        """Extrai recomenda√ß√µes do texto."""
        recommendations = []
        
        patterns = [
            r'[Rr]ecomend[ao]\s+([^.]+)',
            r'[Ss]ugiro\s+([^.]+)',
            r'[Dd]everia[m]?\s+([^.]+)',
            r'√â\s+aconselh√°vel\s+([^.]+)',
            r'[Pp]r√≥ximos?\s+passos?\s*:\s*([^.]+)'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            recommendations.extend([match.strip() for match in matches])
        
        return recommendations[:3]  # Top 3 recomenda√ß√µes
    
    def _determine_analysis_type(self, query: str) -> str:
        """Determina o tipo de an√°lise baseado na query."""
        query_lower = query.lower()
        
        type_patterns = {
            'ranking': ['ranking', 'melhor', 'pior', 'maior', 'menor', 'comparar', 'top'],
            'temporal': ['evolu√ß√£o', 'temporal', 'ao longo', 'tend√™ncia', 'crescimento', 'decl√≠nio'],
            'regional': ['regi√£o', 'regional', 'norte', 'sul', 'nordeste', 'sudeste', 'centro-oeste'],
            'eficiencia': ['efici√™ncia', 'eficiente', 'retorno', 'roi', 'custo-benef√≠cio'],
            'politica': ['pol√≠tica', 'estrat√©gia', 'governamental', 'p√∫blico', 'investimento'],
            'projecao': ['futuro', 'proje√ß√£o', 'previs√£o', 'cen√°rio', 'estimativa']
        }
        
        for analysis_type, keywords in type_patterns.items():
            if any(keyword in query_lower for keyword in keywords):
                return analysis_type
        
        return 'geral'
    
    def _extract_metrics(self, text: str) -> List[str]:
        """Extrai m√©tricas mencionadas no texto."""
        metrics = []
        
        # Padr√µes para m√©tricas
        metric_patterns = [
            r'IDH[:\s]+([0-9.,]+)',
            r'R\$\s*([0-9.,]+)',
            r'([0-9.,]+)%',
            r'([0-9.,]+)\s*milh√µes?',
            r'([0-9.,]+)\s*bilh√µes?'
        ]
        
        for pattern in metric_patterns:
            matches = re.findall(pattern, text)
            metrics.extend(matches)
        
        return metrics[:10]  # Limitar m√©tricas
    
    def _calculate_confidence(self, text: str, context_data: Dict) -> float:
        """Calcula score de confian√ßa da an√°lise."""
        confidence = 0.5  # Base
        
        # Aumentar se h√° dados de contexto
        if context_data:
            confidence += 0.2
        
        # Aumentar se h√° m√©tricas espec√≠ficas
        if re.search(r'\d+[.,]\d+', text):
            confidence += 0.15
        
        # Aumentar se h√° recomenda√ß√µes
        if any(word in text.lower() for word in ['recomendo', 'sugiro', 'deveria']):
            confidence += 0.1
        
        # Diminuir se h√° incertezas
        uncertainty_words = ['talvez', 'possivelmente', 'pode ser', 'incerto']
        for word in uncertainty_words:
            if word in text.lower():
                confidence -= 0.05
        
        return min(max(confidence, 0.0), 1.0)
    
    def _suggest_visualizations(self, analysis_type: str, query: str) -> List[Dict]:
        """Sugere visualiza√ß√µes apropriadas."""
        
        viz_suggestions = {
            'ranking': [
                {'type': 'bar_chart', 'title': 'Ranking de Estados', 'priority': 'high'},
                {'type': 'heatmap', 'title': 'Mapa de Calor', 'priority': 'medium'},
                {'type': 'scatter_plot', 'title': 'Dispers√£o IDH vs Investimento', 'priority': 'medium'}
            ],
            'temporal': [
                {'type': 'line_chart', 'title': 'Evolu√ß√£o Temporal', 'priority': 'high'},
                {'type': 'area_chart', 'title': 'Tend√™ncias Acumuladas', 'priority': 'medium'},
                {'type': 'trend_analysis', 'title': 'An√°lise de Tend√™ncias', 'priority': 'high'}
            ],
            'regional': [
                {'type': 'choropleth_map', 'title': 'Mapa do Brasil', 'priority': 'high'},
                {'type': 'box_plot', 'title': 'Distribui√ß√£o Regional', 'priority': 'medium'},
                {'type': 'radar_chart', 'title': 'Perfil Regional', 'priority': 'medium'}
            ],
            'eficiencia': [
                {'type': 'bubble_chart', 'title': 'Efici√™ncia vs Tamanho', 'priority': 'high'},
                {'type': 'scatter_matrix', 'title': 'Matriz de Correla√ß√£o', 'priority': 'medium'}
            ]
        }
        
        return viz_suggestions.get(analysis_type, [
            {'type': 'generic_chart', 'title': 'Visualiza√ß√£o Geral', 'priority': 'low'}
        ])
    
    def _create_error_response(self, error_msg: str) -> Dict:
        """Cria resposta de erro estruturada."""
        return {
            'response_text': f"Erro na an√°lise: {error_msg}",
            'insights': [],
            'recommendations': [],
            'analysis_type': 'error',
            'metrics_mentioned': [],
            'confidence_score': 0.0,
            'visualization_suggestions': [],
            'timestamp': datetime.now().isoformat(),
            'error': True
        }
    
    def _add_to_history(self, query: str, analysis: Dict):
        """Adiciona an√°lise ao hist√≥rico."""
        self.conversation_history.append({
            'query': query,
            'analysis': analysis,
            'timestamp': datetime.now().isoformat()
        })
        
        # Manter apenas √∫ltimas 10 an√°lises
        if len(self.conversation_history) > 10:
            self.conversation_history = self.conversation_history[-10:]
    
    def generate_executive_summary(self, analyses: List[Dict]) -> str:
        """Gera resumo executivo baseado em m√∫ltiplas an√°lises."""
        if not analyses:
            return "Nenhuma an√°lise dispon√≠vel para resumo."
        
        summary_prompt = f"""
        Com base nas seguintes an√°lises socioecon√¥micas, gere um RESUMO EXECUTIVO:
        
        AN√ÅLISES REALIZADAS:
        {json.dumps([a.get('response_text', '')[:500] for a in analyses], ensure_ascii=False)}
        
        RESUMO DEVE CONTER:
        1. üìä Principais descobertas (3-4 pontos)
        2. üéØ Recomenda√ß√µes estrat√©gicas (2-3 a√ß√µes)
        3. ‚ö†Ô∏è Pontos de aten√ß√£o (riscos/limita√ß√µes)
        4. üìà Pr√≥ximos passos sugeridos
        
        Seja conciso, objetivo e focado em insights acion√°veis.
        """
        
        try:
            response = self.model.generate_content(summary_prompt)
            return response.text
        except Exception as e:
            return f"Erro ao gerar resumo: {str(e)}"
    
    def get_conversation_context(self) -> str:
        """Retorna contexto da conversa atual."""
        if not self.conversation_history:
            return "Nenhuma conversa ativa."
        
        recent_queries = [item['query'] for item in self.conversation_history[-3:]]
        return f"√öltimas consultas: {', '.join(recent_queries)}"
    
    def clear_history(self):
        """Limpa hist√≥rico de conversas."""
        self.conversation_history = []
        self.analysis_cache = {}
        logger.info("üßπ Hist√≥rico de conversas limpo")


# ==================== INTEGRA√á√ÉO COM CONSULTAS DA FASE 3 ====================

class Phase3Integration:
    """Classe para integrar IA com consultas da Fase 3."""
    
    def __init__(self, ai_engine: AIAnalyticsEngine):
        self.ai_engine = ai_engine
    
    def analyze_ranking_results(self, ranking_data: List[Dict], user_query: str = None) -> Dict:
        """Analisa resultados da Consulta 1 com IA."""
        context = {'consulta_1': ranking_data}
        
        if not user_query:
            user_query = "Analise os resultados do ranking IDH vs investimento e forne√ßa insights estrat√©gicos."
        
        return self.ai_engine.analyze_with_ai(user_query, context)
    
    def analyze_temporal_results(self, temporal_data: Dict, user_query: str = None) -> Dict:
        """Analisa resultados da Consulta 2 com IA."""
        context = {'consulta_2': temporal_data}
        
        if not user_query:
            user_query = "Analise a evolu√ß√£o temporal dos indicadores e identifique tend√™ncias importantes."
        
        return self.ai_engine.analyze_with_ai(user_query, context)
    
    def analyze_regional_results(self, regional_data: List[Dict], user_query: str = None) -> Dict:
        """Analisa resultados da Consulta 3 com IA."""
        context = {'consulta_3': regional_data}
        
        if not user_query:
            user_query = "Analise as diferen√ßas regionais e sugira estrat√©gias de desenvolvimento."
        
        return self.ai_engine.analyze_with_ai(user_query, context)
    
    def comprehensive_analysis(self, all_results: Dict, user_query: str = None) -> Dict:
        """An√°lise abrangente com todos os resultados das consultas."""
        if not user_query:
            user_query = "Fa√ßa uma an√°lise abrangente de todos os dados dispon√≠veis e forne√ßa recomenda√ß√µes estrat√©gicas para pol√≠ticas p√∫blicas."
        
        return self.ai_engine.analyze_with_ai(user_query, all_results)


# ==================== FUN√á√ÉO DE CONVENI√äNCIA ====================

def create_ai_analytics_system() -> Tuple[AIAnalyticsEngine, Phase3Integration]:
    """Cria sistema completo de IA anal√≠tica."""
    try:
        ai_engine = AIAnalyticsEngine()
        phase3_integration = Phase3Integration(ai_engine)
        
        logger.info("ü§ñ Sistema de IA Anal√≠tica criado com sucesso")
        return ai_engine, phase3_integration
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao criar sistema de IA: {e}")
        raise 